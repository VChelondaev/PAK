{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Добавляем необходимые модули\n\nimport os\nimport gc\nimport random\nimport librosa as lb\nimport librosa.display as lbd\nimport soundfile as sf\nfrom soundfile import SoundFile \nimport numpy as np \nimport pandas as pd\nfrom tqdm import tqdm\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import average_precision_score\nimport torch\nimport torch.nn as nn\nfrom torch.optim import Adam\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport timm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-26T08:24:17.994587Z","iopub.execute_input":"2023-05-26T08:24:17.995010Z","iopub.status.idle":"2023-05-26T08:24:26.353031Z","shell.execute_reply.started":"2023-05-26T08:24:17.994974Z","shell.execute_reply":"2023-05-26T08:24:26.351938Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Параметры\n\nlearning_rate = 1e-3\nbatch_size = 32\nnum_fold = 5\nnum_classes = 264\nmax_time = 5\nn_mels = 224\nn_fft = 1024\nepochs = 10\nhop_length = 512","metadata":{"execution":{"iopub.status.busy":"2023-05-26T08:24:26.355106Z","iopub.execute_input":"2023-05-26T08:24:26.355660Z","iopub.status.idle":"2023-05-26T08:24:26.361681Z","shell.execute_reply.started":"2023-05-26T08:24:26.355628Z","shell.execute_reply":"2023-05-26T08:24:26.360414Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Блок функций для перевода звука в спектограмму\n\ndef to_rgb(X, eps=1e-6, mean=None, std=None):\n    mean = mean or X.mean()\n    std = std or X.std()\n    X = (X - mean) / (std + eps)\n    _min, _max = X.min(), X.max()\n    if (_max - _min) > eps:\n        V = np.clip(X, _min, _max)\n        V = 255 * (V - _min) / (_max - _min)\n        V = V.astype(np.uint8)\n    else:\n        V = np.zeros_like(X, dtype=np.uint8)\n    return V\n\ndef to_melspec(y, sr, n_mels, fmin, fmax):\n    melspec = lb.feature.melspectrogram(\n        y=y, sr=sr, n_mels=n_mels, fmin=fmin, fmax=fmax,\n    )\n    melspec = lb.power_to_db(melspec).astype(np.float32)\n    return melspec","metadata":{"execution":{"iopub.status.busy":"2023-05-26T08:24:26.367946Z","iopub.execute_input":"2023-05-26T08:24:26.368573Z","iopub.status.idle":"2023-05-26T08:24:26.378739Z","shell.execute_reply.started":"2023-05-26T08:24:26.368542Z","shell.execute_reply":"2023-05-26T08:24:26.377789Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class ClefDataset(Dataset):\n    def __init__(self, data, sr=32000, n_mels=128, fmin=0, fmax=None, duration=5, \n                 step=None, res_type=\"kaiser_fast\", resample=True, valid=False, transform=None):\n        self.data = data\n        self.sr = sr\n        self.n_mels = n_mels\n        self.fmin = fmin\n        self.fmax = fmax or self.sr // 2\n        self.transform = transform\n        self.duration = duration\n        self.audio_length = self.duration*self.sr\n        self.step = step or self.audio_length\n        self.valid = valid\n        self.path = '' if valid else 'kaggle/input/train_audio/'\n        self.res_type = res_type\n        self.resample = resample\n        \n    # Приводим значения к диапазону (0, 1)\n    def normalize(self, image):\n        image = image.astype(\"float32\", copy=False) / 255.0\n        if image.shape[1] > 256:\n            image = image[:128, :256]\n        else:\n            zeroes = np.zeros((128, 256 - image.shape[1]))\n            image = np.concatenate([image, zeroes], axis=1, dtype=np.float32)\n        image = np.stack([image, image, image], axis=0)\n        return image\n    \n    def audio_to_image(self, audio):\n        melspec = to_melspec(audio, self.sr, self.n_mels, self.fmin, self.fmax) \n        image = to_rgb(melspec)\n        image = self.normalize(image)\n        return image\n\n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        row = self.data.loc[idx]\n        filepath = self.path + str(row['path'])\n        audio, orig_sr = sf.read(filepath, dtype=\"float32\")\n        if self.resample and orig_sr != self.sr:\n            audio = lb.resample(audio, orig_sr, self.sr, res_type=self.res_type)\n        if self.valid:\n            audios = []\n            for i in range(self.audio_length, len(audio) + self.step, self.step):\n                start = max(0, i - self.audio_length)\n                end = start + self.audio_length\n                audios.append(audio[start:end])\n            if len(audios[-1]) < self.audio_length:\n                audios = audios[:-1]\n            images = [self.audio_to_image(audio) for audio in audios]\n            images = np.stack(images)\n        else:\n            images = self.audio_to_image(audio) \n        labels = torch.tensor(row[3:]).float() \n        return (images, labels)","metadata":{"execution":{"iopub.status.busy":"2023-05-26T08:24:26.380043Z","iopub.execute_input":"2023-05-26T08:24:26.380546Z","iopub.status.idle":"2023-05-26T08:24:26.399905Z","shell.execute_reply.started":"2023-05-26T08:24:26.380516Z","shell.execute_reply":"2023-05-26T08:24:26.398865Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose(\n    [transforms.ToTensor(), transforms.Resize((120, 224))])\ndata = pd.read_csv('/kaggle/input/birdclef-2023/train_metadata.csv')\ndata = pd.concat(\n    [\n        pd.Series(data['primary_label']), \n        pd.Series(data['type']), \n        pd.Series(data['filename'], name='path')\n    ], \n    axis=1, names=['primary_label', 'type', 'path']\n)\nbirds = list(pd.get_dummies(data['primary_label']).columns)\nfilenames = data.path.values.tolist()\ndata = pd.concat([data, pd.get_dummies(data['primary_label'])], axis=1)\ntrain_data, valid_data = train_test_split(data, train_size=0.7, shuffle=True)\ntrain_data = train_data.reset_index(drop=True)\nvalid_data = valid_data.reset_index(drop=True)\n\ntrain_dataset = ClefDataset(train_data, transform=transform)\ntrain_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n\nvalid_dataset = ClefDataset(valid_data)\nvalid_dataloader = DataLoader(valid_dataset, shuffle=True, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-05-26T08:24:26.401670Z","iopub.execute_input":"2023-05-26T08:24:26.402440Z","iopub.status.idle":"2023-05-26T08:24:26.712455Z","shell.execute_reply.started":"2023-05-26T08:24:26.402403Z","shell.execute_reply":"2023-05-26T08:24:26.711306Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.model = timm.create_model(\"tf_efficientnet_b1_ns\", pretrained=False)\n        self.in_features = self.model.classifier.in_features\n        self.model.classifier = nn.Sequential(nn.Linear(self.in_features, num_classes))\n    \n    def forward(self, images):\n        features = self.model(images)\n        return features","metadata":{"execution":{"iopub.status.busy":"2023-05-26T08:24:26.713892Z","iopub.execute_input":"2023-05-26T08:24:26.714558Z","iopub.status.idle":"2023-05-26T08:24:26.724667Z","shell.execute_reply.started":"2023-05-26T08:24:26.714513Z","shell.execute_reply":"2023-05-26T08:24:26.723560Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# default метрика от Kaggle\ndef padded_cmap(solution, submission, padding_factor=5):\n    solution = solution.drop(['row_id'], axis=1, errors='ignore')\n    submission = submission.drop(['row_id'], axis=1, errors='ignore')\n    \n    new_rows = []\n    for i in range(padding_factor):\n        new_rows.append([1 for i in range(len(solution.columns))])\n    new_rows = pd.DataFrame(new_rows)\n    new_rows.columns = solution.columns\n    \n    padded_solution = pd.concat([solution, new_rows]).reset_index(drop=True).copy()\n    padded_submission = pd.concat([submission, new_rows]).reset_index(drop=True).copy()\n    \n    score = sklearn.metrics.average_precision_score(\n        padded_solution.values,\n        padded_submission.values,\n        average='macro',\n    )\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-05-26T08:24:26.726516Z","iopub.execute_input":"2023-05-26T08:24:26.727344Z","iopub.status.idle":"2023-05-26T08:24:26.740137Z","shell.execute_reply.started":"2023-05-26T08:24:26.727302Z","shell.execute_reply":"2023-05-26T08:24:26.738987Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def loss_fn(outputs, labels):\n    return  nn.CrossEntropyLoss()(outputs, labels)\n\ndef train(model, data_loader, optimizer, epoch):\n    model.train()\n    running_loss = 0\n    loop = tqdm(data_loader, position=0)\n    for i, (mels, labels) in enumerate(loop):\n        \n        outputs = model(mels)\n        _, preds = torch.max(outputs, 1)\n       \n        loss = loss_fn(outputs, labels)\n        \n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n            \n        del mels, labels, outputs\n        gc.collect()\n            \n        running_loss += loss.item()\n        \n        loop.set_description(f\"Epoch [{epoch+1}/{epochs}]\")\n        loop.set_postfix(loss=loss.item())\n\n    return running_loss / len(data_loader)\n\ndef valid(model, data_loader, epoch):\n    model.eval()\n    \n    running_loss = 0\n    pred = []\n    label = []\n    \n    loop = tqdm(data_loader, position=0)\n    for i, (mels, labels) in enumerate(loop):\n        \n        outputs = model(mels)\n        _, preds = torch.max(outputs, 1)\n       \n        loss = loss_fn(outputs, labels)\n            \n        running_loss += loss.item()\n        \n        loop.set_description(f\"Epoch [{epoch+1}/{epochs}]\")\n        loop.set_postfix(loss=loss.item())\n\n        label.append(labels.cpu().detach())\n        pred.append(outputs.sigmoid().cpu().detach())\n        \n        del mels, labels, outputs\n        gc.collect()\n        \n    labels_df = torch.cat([x for x in label], dim=0)\n    pred_df = torch.cat([x for x in pred], dim=0)\n    label_df = pd.DataFrame(labels_df)  \n    pred_df = pd.DataFrame(pred_df)  \n    current_score = padded_cmap(label_df, pred_df)\n    \n    return running_loss/len(data_loader), current_score","metadata":{"execution":{"iopub.status.busy":"2023-05-26T08:24:26.741701Z","iopub.execute_input":"2023-05-26T08:24:26.742393Z","iopub.status.idle":"2023-05-26T08:24:26.761544Z","shell.execute_reply.started":"2023-05-26T08:24:26.742349Z","shell.execute_reply":"2023-05-26T08:24:26.760148Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model = Model()\noptimizer = Adam(model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2023-05-26T08:24:26.766260Z","iopub.execute_input":"2023-05-26T08:24:26.767631Z","iopub.status.idle":"2023-05-26T08:24:27.088550Z","shell.execute_reply.started":"2023-05-26T08:24:26.767581Z","shell.execute_reply":"2023-05-26T08:24:27.087311Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/timm/models/_factory.py:114: UserWarning: Mapping deprecated model name tf_efficientnet_b1_ns to current tf_efficientnet_b1.ns_jft_in1k.\n  model = create_fn(\n","output_type":"stream"}]},{"cell_type":"code","source":"'''best_valid_padded_map = 0\n\nfor epoch in range(epochs):\n    train_loss = train(model, train_dataloader, optimizer, epoch)\n    valid_loss, valid_padded_map = valid(model, valid_dataloader, epoch)\n\n    print(f'mAP: {valid_padded_map}, loss: {valid_loss}')\n    if valid_padded_map > best_valid_padded_map:\n        torch.save(model.state_dict(), f'./ckp.bin')\n        best_valid_padded_map = valid_padded_map\n                                    \nprint(f'End of training. Best score: {best_valid_padded_map}')\nprint(best_valid_padded_map)'''\n\n\ninput_file_name = os.listdir('/kaggle/input/birdclef-2023/test_soundscapes')\ninput_file_path = '/kaggle/input/birdclef-2023/test_soundscapes/'\n\ndata = {'primary_label' : [x for x in range(len(input_file_name))], \n        'type' : [x for x in range(len(input_file_name))], \n        'path' : [str(input_file_path + x) for x in input_file_name]}\n\ntest_data = pd.DataFrame(data=data)\ntest_data = ClefDataset(test_data, valid=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-26T08:24:27.090422Z","iopub.execute_input":"2023-05-26T08:24:27.092169Z","iopub.status.idle":"2023-05-26T08:24:27.107895Z","shell.execute_reply.started":"2023-05-26T08:24:27.092122Z","shell.execute_reply":"2023-05-26T08:24:27.106213Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model = Model()\nmodel.load_state_dict(torch.load(\"/kaggle/input/birdclef-weights/best.pth\", \n                                 map_location='cpu'), strict=False)\npredictions = []\nfor en in range(len(test_data)):\n    images = torch.from_numpy(test_data[en][0])\n    with torch.no_grad():\n        outputs = model(images).sigmoid().detach().cpu().numpy()\n    predictions.append(outputs)","metadata":{"execution":{"iopub.status.busy":"2023-05-26T08:24:27.109746Z","iopub.execute_input":"2023-05-26T08:24:27.110461Z","iopub.status.idle":"2023-05-26T08:25:00.030972Z","shell.execute_reply.started":"2023-05-26T08:24:27.110415Z","shell.execute_reply":"2023-05-26T08:25:00.029765Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/timm/models/_factory.py:114: UserWarning: Mapping deprecated model name tf_efficientnet_b1_ns to current tf_efficientnet_b1.ns_jft_in1k.\n  model = create_fn(\n","output_type":"stream"}]},{"cell_type":"code","source":"submission = pd.DataFrame(columns=['row_id']+birds)\n\nfor i, file in enumerate(input_file_name):\n    pred = predictions[i]\n    file = input_file_name[i][:-4]\n    num_rows = len(pred)\n    row_ids = [f'{file}_{(i+1)*5}' for i in range(num_rows)]\n    df = pd.DataFrame(columns=['row_id'] + birds)\n    df['row_id'] = row_ids\n    df[birds] = pred\n    submission = pd.concat([submission, df]).reset_index(drop=True)\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-26T08:25:00.032539Z","iopub.execute_input":"2023-05-26T08:25:00.033359Z","iopub.status.idle":"2023-05-26T08:25:00.218195Z","shell.execute_reply.started":"2023-05-26T08:25:00.033323Z","shell.execute_reply":"2023-05-26T08:25:00.217110Z"},"trusted":true},"execution_count":12,"outputs":[]}]}